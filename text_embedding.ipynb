{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evanturkon/miniconda3/envs/ascii/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ast\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import einsum\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "from ascii_utils import ASCIITransformer, ASCIITokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using apple metal GPU\n"
     ]
    }
   ],
   "source": [
    "# check for GPU\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using apple metal GPU\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using nvidia GPU\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ASCIITokenizer:\n",
    "#     def __init__(self):\n",
    "#         self.vocab = [chr(i) for i in range(32, 127)] + ['']\n",
    "#         self.vocab_size = len(self.vocab)\n",
    "#         self.token_to_char = {i: c for i, c in enumerate(self.vocab)}\n",
    "#         self.char_to_token = {c: i for i, c in enumerate(self.vocab)}\n",
    "\n",
    "#     def tokenize(self, text):\n",
    "#         tokens = [self.char_to_token[c] for c in text if c in self.vocab]\n",
    "#         return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pad_ascii_art(ascii_art, max_width=32, max_height=32, pad_char=' '):\n",
    "#     lines = ascii_art.splitlines()\n",
    "#     padded_lines = [line.ljust(max_width, pad_char) for line in lines]\n",
    "#     while len(padded_lines) < max_height:\n",
    "#         padded_lines.append(pad_char * max_width)\n",
    "#     return '\\n'.join(padded_lines)\n",
    "\n",
    "# df = pd.read_json(\"./ascii_data/ascii_art_data.json\")\n",
    "# df['width'] = df['text'].apply(lambda x: max(len(line) for line in x.splitlines()))\n",
    "# df['height'] = df['text'].apply(lambda x: len(x.splitlines()))\n",
    "# df['text'] = df['text'].apply(pad_ascii_art)\n",
    "\n",
    "# df = df[ (df['width'] < 32) & (df['height'] < 32) ][['topic', 'text']]\n",
    "\n",
    "# sentence_transformer_model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "# embedding_model = SentenceTransformer(sentence_transformer_model).to(device)\n",
    "# def encode(x):\n",
    "#     return embedding_model.encode(x)\n",
    "# embeddings = df['text'].apply(encode)\n",
    "# df['embedding'] = [repr(list(e)) for e in embeddings]\n",
    "# df.to_csv('ascii_embeddings.csv', index=False)\n",
    "# df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvarks</td>\n",
       "      <td>_.---._    /\\\\           \\n    ./'     ...</td>\n",
       "      <td>[-0.07842264, 0.07851021, -0.029405361, -0.022...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bats</td>\n",
       "      <td>_   ,_,   _             \\n       / `'=...</td>\n",
       "      <td>[-0.074843615, 0.031718493, 0.11798973, 0.0175...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bats</td>\n",
       "      <td>(_    ,_,    _)          \\n       / `'-...</td>\n",
       "      <td>[-0.09386347, 0.02620181, 0.065080315, -0.0151...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topic                                               text  \\\n",
       "0  aardvarks         _.---._    /\\\\           \\n    ./'     ...   \n",
       "1       bats          _   ,_,   _             \\n       / `'=...   \n",
       "2       bats         (_    ,_,    _)          \\n       / `'-...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.07842264, 0.07851021, -0.029405361, -0.022...  \n",
       "1  [-0.074843615, 0.031718493, 0.11798973, 0.0175...  \n",
       "2  [-0.09386347, 0.02620181, 0.065080315, -0.0151...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ascii_embeddings.csv')\n",
    "df['embedding'] = df['embedding'].apply(ast.literal_eval)\n",
    "print(type(df['embedding'][0]))\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASCIIDataLoader(Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        # df = df.reset_index()\n",
    "        self.labels = df['topic']\n",
    "        tokenized_data = [tokenizer.tokenize(art) for art in df['text']]\n",
    "        max_length = 32 * 32\n",
    "        tokenized_data = [tokens + [0] * (max_length - len(tokens)) for tokens in tokenized_data]\n",
    "        self.asciis = torch.tensor(tokenized_data)\n",
    "        self.embedding = torch.tensor(df['embedding'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.embedding, self.labels[idx], self.asciis[idx]\n",
    "\n",
    "dataset = ASCIIDataLoader(df, ASCIITokenizer())\n",
    "loader = DataLoader(dataset, batch_size=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__==\"__main__\":\n",
    "    model = ASCIITransformer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "loader = iter(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(10):\n",
    "    for embedding, _, ascii_text in loader:\n",
    "        print(embedding)\n",
    "        print(ascii_text)\n",
    "        ascii_text = ascii_text.to(device)\n",
    "        embedding = embedding.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(embedding)\n",
    "        loss = criterion(outputs.view(-1), ascii_text.view(-1).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
